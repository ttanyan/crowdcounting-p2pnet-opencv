import argparse
import cv2
import numpy as np
import os
import datetime
import random


class AnchorPoints():
    def __init__(self, pyramid_levels=None, strides=None, row=2, line=2):
        # 无人机视角下，row/line 设为 2x2 通常比 3x3 在小目标上更平衡
        self.pyramid_levels = pyramid_levels if pyramid_levels is not None else [3]
        self.strides = strides if strides is not None else [2 ** x for x in self.pyramid_levels]
        self.row = row
        self.line = line

    def generate_anchor_points(self, stride=8, row=2, line=2):
        # 矢量化生成 anchor 偏移
        row_step = stride / row
        line_step = stride / line
        shift_x = (np.arange(1, line + 1) - 0.5) * line_step - stride / 2
        shift_y = (np.arange(1, row + 1) - 0.5) * row_step - stride / 2
        shift_x, shift_y = np.meshgrid(shift_x, shift_y)
        return np.stack([shift_x.ravel(), shift_y.ravel()], axis=1)

    def shift(self, shape, stride, anchor_points):
        # 优化后的 shift 函数，减少内存拷贝
        y, x = np.mgrid[0:shape[0], 0:shape[1]]
        shifts = np.stack([(x.ravel() + 0.5) * stride, (y.ravel() + 0.5) * stride], axis=1)

        # 使用 broadcasting 快速计算所有 anchor 坐标
        all_anchors = shifts[:, np.newaxis, :] + anchor_points[np.newaxis, :, :]
        return all_anchors.reshape(-1, 2)

    def __call__(self, image_shape_hw):
        # 传入 HW 即可，无需整个图像 blob
        all_anchor_points = []
        for idx, p in enumerate(self.pyramid_levels):
            stride = 2 ** p
            # 计算当前特征层的大小
            f_h, f_w = (image_shape_hw[0] + stride - 1) // stride, (image_shape_hw[1] + stride - 1) // stride
            anchors = self.generate_anchor_points(stride, row=self.row, line=self.line)
            shifted = self.shift((f_h, f_w), self.strides[idx], anchors)
            all_anchor_points.append(shifted)

        return np.concatenate(all_anchor_points, axis=0).astype(np.float32)


class P2PNet():
    def __init__(self, model_path, conf_threshold=0.511, use_gpu=False):
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"找不到模型文件: {model_path}")

        self.net = cv2.dnn.readNet(model_path)
        if use_gpu:
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)

        self.conf_threshold = conf_threshold
        # ImageNet 标准归一化参数
        self.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
        self.std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
        # SHTechA 预训练模型通常对应 pyramid_levels=[3], row=2, line=2
        self.anchor_gen = AnchorPoints(pyramid_levels=[3], row=2, line=2)

    def _sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def detect(self, srcimg):
        h, w = srcimg.shape[:2]
        # 128 对齐，防止网络下采样时的维度不匹配
        new_w, new_h = (w // 128) * 128, (h // 128) * 128

        # 预处理优化：直接在 blobFromImage 中完成归一化会更快
        # 但由于 OpenCV 默认只支持减均值，不支持除以标准差，所以仍手动处理或在网络中集成
        blob_img = cv2.resize(srcimg, (new_w, new_h))
        blob_img = cv2.cvtColor(blob_img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0
        blob_img = (blob_img - self.mean) / self.std

        blob = cv2.dnn.blobFromImage(blob_img)

        self.net.setInput(blob)
        # 获取输出节点：pred_logits (置信度), pred_points (偏移量)
        out_names = self.net.getUnconnectedOutLayersNames()
        preds = self.net.forward(out_names)

        # 解析输出
        # 不同导出方式输出顺序可能不同，需通过 shape 判定
        logits = preds[0] if preds[0].shape[-1] == 1 else preds[1]
        offset = preds[1] if preds[1].shape[-1] == 2 else preds[0]

        # 获取 Anchor Points
        anchors = self.anchor_gen((new_h, new_w))

        # 计算最终坐标
        scores = self._sigmoid(logits.flatten())
        points = offset.reshape(-1, 2) + anchors

        # 过滤
        keep = scores > self.conf_threshold
        final_scores = scores[keep]
        final_points = points[keep]

        # 映射回原图尺寸
        final_points[:, 0] *= (w / new_w)
        final_points[:, 1] *= (h / new_h)

        return final_scores, final_points


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--imgpath', default='imgs/img_5.png')
    parser.add_argument('--onnx_path', default='weight/SHTechA.onnx')
    parser.add_argument('--gpu', action='store_true', help="是否使用 CUDA")
    args = parser.parse_args()

    # 初始化
    detector = P2PNet(args.onnx_path, use_gpu=args.gpu)

    # 读取图像
    frame = cv2.imread(args.imgpath)
    if frame is None:
        print("tu")
        exit()

    # 检测
    scores, points = detector.detect(frame)

    # 绘制结果
    for pt in points:
        cv2.circle(frame, (int(pt[0]), int(pt[1])), 3, (0, 255, 0), -1)

    # 显示计数
    cv2.putText(frame, f"Count: {len(points)}", (30, 50),
                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)

    print(f"检测完成，人数: {len(points)}")

    # 创建保存目录
    output_dir = "image_test"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # 生成时间戳加随机数的文件名
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    random_num = random.randint(1000, 9999)
    filename = f"{output_dir}/result_{timestamp}_{random_num}.jpg"
    
    # 保存结果图片
    cv2.imwrite(filename, frame)
    print(f"检测结果已保存到: {filename}")

    # 窗口展示优化（针对大图缩小展示）
    h, w = frame.shape[:2]
    show_w = 1280
    show_h = int(h * (show_w / w))
    cv2.namedWindow('P2PNet Drone View', cv2.WINDOW_NORMAL)
    cv2.resizeWindow('P2PNet Drone View', show_w, show_h)
    cv2.imshow('P2PNet Drone View', frame)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
